import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer

# --- Configuration ---
st.set_page_config(page_title="NSL-KDD Intrusion Detector", layout="wide")

# Define the list of selected features based on provided importance
selected_features = [
Â  Â  "byte_ratio",
Â  Â  "src_bytes",
Â  Â  "byte_diff",
Â  Â  "service",
Â  Â  "diff_srv_rate",
Â  Â  "flag",
Â  Â  "same_srv_rate",
Â  Â  "dst_bytes",
Â  Â  "dst_host_diff_srv_rate",
Â  Â  "dst_host_srv_count",
Â  Â  "count",
Â  Â  "protocol_type"
]

# Numerical features for sliders
numerical_features = [
Â  Â  "byte_ratio",
Â  Â  "src_bytes",
Â  Â  "byte_diff",
Â  Â  "diff_srv_rate",
Â  Â  "same_srv_rate",
Â  Â  "dst_bytes",
Â  Â  "dst_host_diff_srv_rate",
Â  Â  "dst_host_srv_count",
Â  Â  "count"
]

# Categorical features for dropdowns
categorical_features = ["service", "flag", "protocol_type"]

# Define common values for dropdowns (based on NSL-KDD dataset)
service_options = [
Â  Â  "http", "ftp", "telnet", "smtp", "finger", "domain_u", "auth", "pop_3",
Â  Â  "ftp_data", "other", "private", "domain", "echo", "irc", "ssh"
]
flag_options = [
Â  Â  "SF", "S0", "REJ", "RSTR", "RSTO", "S1", "S2", "S3", "OTH", "RSTOS0", "SH"
]
protocol_type_options = ["tcp", "udp", "icmp"]

# --- Data Loading and Preprocessing ---
@st.cache_data
def load_and_preprocess_data():
Â  Â  try:
Â  Â  Â  Â  # Column names
Â  Â  Â  Â  feature = ["duration","protocol_type","service","flag","src_bytes","dst_bytes","land","wrong_fragment","urgent","hot",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "num_failed_logins","logged_in","num_compromised","root_shell","su_attempted","num_root",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "num_file_creations","num_shells","num_access_files","num_outbound_cmds","is_host_login",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "is_guest_login","count","srv_count","serror_rate","srv_serror_rate","rerror_rate","srv_rerror_rate",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "same_srv_rate","diff_srv_rate","srv_diff_host_rate","dst_host_count","dst_host_srv_count",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "dst_host_same_srv_rate","dst_host_diff_srv_rate","dst_host_same_src_port_rate",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "dst_host_srv_diff_host_rate","dst_host_serror_rate","dst_host_srv_serror_rate",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "dst_host_rerror_rate","dst_host_srv_rerror_rate","label","difficulty"]

Â  Â  Â  Â  # Load dataset from URL
Â  Â  Â  Â  train_url = "https://raw.githubusercontent.com/blurerjr/Improving_IDS_/refs/heads/master/KDDTrain%2B.txt"
Â  Â  Â  Â  train_data = pd.read_csv(train_url, names=feature)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Drop 'difficulty' column
Â  Â  Â  Â  train_data = train_data.drop(['difficulty'], axis=1)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Compute derived features
Â  Â  Â  Â  train_data['byte_ratio'] = train_data['src_bytes'] / (train_data['dst_bytes'] + 1)Â  # Avoid division by zero
Â  Â  Â  Â  train_data['byte_diff'] = train_data['src_bytes'] - train_data['dst_bytes']
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Function to convert attack labels
Â  Â  Â  Â  def change_label(df):
Â  Â  Â  Â  Â  Â  df = df.copy()
Â  Â  Â  Â  Â  Â  df['label'] = df['label'].replace(
Â  Â  Â  Â  Â  Â  Â  Â  ['apache2','back','land','neptune','mailbomb','pod','processtable','smurf','teardrop','udpstorm','worm'], 'Dos')
Â  Â  Â  Â  Â  Â  df['label'] = df['label'].replace(
Â  Â  Â  Â  Â  Â  Â  Â  ['ftp_write','guess_passwd','httptunnel','imap','multihop','named','phf','sendmail',
Â  Â  Â  Â  Â  Â  Â  Â  Â 'snmpgetattack','snmpguess','spy','warezclient','warezmaster','xlock','xsnoop'], 'R2L')
Â  Â  Â  Â  Â  Â  df['label'] = df['label'].replace(
Â  Â  Â  Â  Â  Â  Â  Â  ['ipsweep','mscan','nmap','portsweep','saint','satan'], 'Probe')
Â  Â  Â  Â  Â  Â  df['label'] = df['label'].replace(
Â  Â  Â  Â  Â  Â  Â  Â  ['buffer_overflow','loadmodule','perl','ps','rootkit','sqlattack','xterm'], 'U2R')
Â  Â  Â  Â  Â  Â  return df
Â  Â  Â  Â Â 
Â  Â  Â  Â  train_data = change_label(train_data)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Create a copy for processing
Â  Â  Â  Â  multi_data = train_data.copy()
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Normalize numerical columns
Â  Â  Â  Â  std_scaler = StandardScaler()
Â  Â  Â  Â  numeric_col = multi_data.select_dtypes(include='number').columns
Â  Â  Â  Â  for col in numeric_col:
Â  Â  Â  Â  Â  Â  arr = multi_data[col].values
Â  Â  Â  Â  Â  Â  multi_data[col] = std_scaler.fit_transform(arr.reshape(-1, 1))
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Encode labels
Â  Â  Â  Â  label_encoder = LabelEncoder()
Â  Â  Â  Â  multi_data['intrusion'] = label_encoder.fit_transform(multi_data['label'])
Â  Â  Â  Â  multi_data = multi_data.drop(labels=['label'], axis=1)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # One-hot encode categorical columns
Â  Â  Â  Â  multi_data = pd.get_dummies(multi_data, columns=['protocol_type','service','flag'], prefix="", prefix_sep="")
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Calculate feature statistics for slider ranges
Â  Â  Â  Â  stats_df = multi_data.select_dtypes(include='number').describe().loc[['min', 'max', '50%']].transpose()
Â  Â  Â  Â  stats_df = stats_df.replace([np.inf, -np.inf], np.nan).fillna(0)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Separate features and labels
Â  Â  Â  Â  X = multi_data.drop(labels=['intrusion'], axis=1)
Â  Â  Â  Â  y = multi_data['intrusion']
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Impute missing values
Â  Â  Â  Â  imputer = SimpleImputer(strategy='median')
Â  Â  Â  Â  X_imputed = imputer.fit_transform(X)
Â  Â  Â  Â  X = pd.DataFrame(X_imputed, columns=X.columns)
Â  Â  Â  Â Â 
Â  Â  Â  Â  return X, y, label_encoder, imputer, stats_df
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Error loading or preprocessing data: {str(e)}")
Â  Â  Â  Â  return None, None, None, None, None

# Load and preprocess the data, and get feature statistics
data_load_state = st.info("Loading data and preprocessing...")
try:
Â  Â  X, y_encoded, label_encoder, imputer, stats_df = load_and_preprocess_data()
Â  Â  data_load_state.empty()
except Exception as e:
Â  Â  data_load_state.error(f"An error occurred during data loading and preprocessing: {e}")
Â  Â  X, y_encoded, label_encoder, imputer, stats_df = None, None, None, None, None

# Check if data loaded successfully
if X is not None and y_encoded is not None and label_encoder is not None and imputer is not None and stats_df is not None:
Â  Â  st.title("ðŸ¤– NSL-KDD Intrusion Detector")
Â  Â  st.write("Use the sidebar to enter the feature values and predict the type of activity.")
Â  Â  st.write("Tip: For attacks, try high values for `count`, `diff_srv_rate`, or select `service=private`, `flag=S0`, `protocol_type=tcp`.")

Â  Â  # --- Optional: Display Raw Data ---
Â  Â  with st.expander('Show Raw Data (from GitHub)'):
Â  Â  Â  Â  st.write("This is the preprocessed data loaded from your GitHub repository.")
Â  Â  Â  Â  st.dataframe(X.head())
Â  Â  Â  Â  st.write("Label counts:")
Â  Â  Â  Â  st.write(pd.Series(label_encoder.inverse_transform(y_encoded)).value_counts())

Â  Â  # --- Model Training ---
Â  Â  @st.cache_resource
Â  Â  def train_model(features, target):
Â  Â  Â  Â  st.info("Training the Random Forest model...")
Â  Â  Â  Â  model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced')
Â  Â  Â  Â  model.fit(features, target)
Â  Â  Â  Â  st.success("Model training complete!")
Â  Â  Â  Â  return model

Â  Â  # Train the model
Â  Â  rf_model = train_model(X, y_encoded)

Â  Â  # --- Feature Importance ---
Â  Â  st.header("Feature Importance")
Â  Â  st.write("Shows which features the model considers most important for classification.")

Â  Â  importances = rf_model.feature_importances_
Â  Â  feature_names = X.columns
Â  Â  feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})
Â  Â  feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)

Â  Â  st.dataframe(feature_importance_df.head(20), hide_index=True)

Â  Â  st.subheader("Feature Importance Bar Chart")
Â  Â  fig, ax = plt.subplots(figsize=(10, 6))
Â  Â  sns.barplot(x='importance', y='feature', data=feature_importance_df.head(20), ax=ax)
Â  Â  ax.set_title('Top 20 Feature Importance from Random Forest')
Â  Â  ax.set_xlabel('Importance')
Â  Â  ax.set_ylabel('Feature')
Â  Â  plt.tight_layout()
Â  Â  st.pyplot(fig)

Â  Â  # --- Input Features Section (Sidebar, Using Sliders and Dropdowns) ---
Â  Â  with st.sidebar:
Â  Â  Â  Â  st.header("Input Features")
Â  Â  Â  Â  st.write("Adjust the sliders and dropdowns below to get a prediction.")
Â  Â  Â  Â  st.write("Numerical ranges are normalized. High `count` or `diff_srv_rate` may indicate attacks.")

Â  Â  Â  Â  # Numerical inputs (sliders)
Â  Â  Â  Â  input_data = {}
Â  Â  Â  Â  valid_numerical_features = [f for f in numerical_features if f in X.columns and f in stats_df.index]
Â  Â  Â  Â  if not valid_numerical_features:
Â  Â  Â  Â  Â  Â  st.error("No valid numerical features available for input. Please check feature selection.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  for feature in valid_numerical_features:
Â  Â  Â  Â  Â  Â  Â  Â  min_val = float(stats_df.loc[feature, 'min'])
Â  Â  Â  Â  Â  Â  Â  Â  max_val = float(stats_df.loc[feature, 'max'])
Â  Â  Â  Â  Â  Â  Â  Â  median_val = float(stats_df.loc[feature, '50%'])
Â  Â  Â  Â  Â  Â  Â  Â  if min_val == max_val:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  input_data[feature] = st.number_input(f"{feature}", value=min_val, key=f"sidebar_input_{feature}")
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  input_data[feature] = st.slider(f"{feature}", min_value=min_val, max_value=max_val, value=median_val, key=f"sidebar_input_{feature}")

Â  Â  Â  Â  # Categorical inputs (dropdowns)
Â  Â  Â  Â  st.subheader("Categorical Features")
Â  Â  Â  Â  categorical_inputs = {}
Â  Â  Â  Â  categorical_inputs['service'] = st.selectbox("Service", options=service_options, key="sidebar_input_service")
Â  Â  Â  Â  categorical_inputs['flag'] = st.selectbox("Flag", options=flag_options, key="sidebar_input_flag")
Â  Â  Â  Â  categorical_inputs['protocol_type'] = st.selectbox("Protocol Type", options=protocol_type_options, key="sidebar_input_protocol_type")

Â  Â  Â  Â  # Test attack input button
Â  Â  Â  Â  if st.button("Test Attack Input (Dos-like)"):
Â  Â  Â  Â  Â  Â  # Sample values for a Dos attack (based on NSL-KDD attack patterns)
Â  Â  Â  Â  Â  Â  input_data = {
Â  Â  Â  Â  Â  Â  Â  Â  'byte_ratio': 2.0,Â  # High src_bytes relative to dst_bytes
Â  Â  Â  Â  Â  Â  Â  Â  'src_bytes': 3.0,Â  Â # High normalized value
Â  Â  Â  Â  Â  Â  Â  Â  'byte_diff': 2.5,Â  Â # Large difference
Â  Â  Â  Â  Â  Â  Â  Â  'diff_srv_rate': 1.5,Â  # High for attacks
Â  Â  Â  Â  Â  Â  Â  Â  'same_srv_rate': -1.0, # Low for attacks
Â  Â  Â  Â  Â  Â  Â  Â  'dst_bytes': 0.0,Â  Â # Often low in attacks
Â  Â  Â  Â  Â  Â  Â  Â  'dst_host_diff_srv_rate': 1.0,Â  # High for attacks
Â  Â  Â  Â  Â  Â  Â  Â  'dst_host_srv_count': -1.0,Â  # Low for attacks
Â  Â  Â  Â  Â  Â  Â  Â  'count': 2.0Â  Â  Â  Â  # High connection count
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  categorical_inputs = {
Â  Â  Â  Â  Â  Â  Â  Â  'service': 'private',Â  # Common in attacks
Â  Â  Â  Â  Â  Â  Â  Â  'flag': 'S0',Â  Â  Â  Â  Â # Common in Dos attacks
Â  Â  Â  Â  Â  Â  Â  Â  'protocol_type': 'tcp'
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  # --- Prediction Button ---
Â  Â  Â  Â  st.header("Detect Intrusion")
Â  Â  Â  Â  st.info("Use the button below to detect intrusion in the input network data.")
Â  Â  Â  Â  if st.button("Detect Activity"):
Â  Â  Â  Â  Â  Â  # Prepare input data for prediction efficiently
Â  Â  Â  Â  Â  Â  input_df = pd.DataFrame([input_data])
Â  Â  Â  Â  Â  Â  # Create a DataFrame with all columns initialized to 0
Â  Â  Â  Â  Â  Â  full_input_df = pd.DataFrame(0.0, index=[0], columns=X.columns)
Â  Â  Â  Â  Â  Â  # Update numerical features
Â  Â  Â  Â  Â  Â  for col in input_data:
Â  Â  Â  Â  Â  Â  Â  Â  full_input_df[col] = input_data[col]
Â  Â  Â  Â  Â  Â  # Update categorical features (set one-hot encoded columns)
Â  Â  Â  Â  Â  Â  for feature, value in categorical_inputs.items():
Â  Â  Â  Â  Â  Â  Â  Â  if feature == 'service':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  col_name = value if value != 'other' else 'other'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if col_name in X.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  full_input_df[col_name] = 1.0
Â  Â  Â  Â  Â  Â  Â  Â  elif feature == 'flag' or feature == 'protocol_type':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if value in X.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  full_input_df[value] = 1.0
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Impute and predict
Â  Â  Â  Â  Â  Â  input_imputed = imputer.transform(full_input_df)
Â  Â  Â  Â  Â  Â  input_processed_df = pd.DataFrame(input_imputed, columns=X.columns)

Â  Â  Â  Â  Â  Â  # Make prediction
Â  Â  Â  Â  Â  Â  prediction_encoded = rf_model.predict(input_processed_df)
Â  Â  Â  Â  Â  Â  predicted_label_raw = label_encoder.inverse_transform(prediction_encoded)[0]

Â  Â  Â  Â  Â  Â  # Display prediction
Â  Â  Â  Â  Â  Â  st.subheader("Detection Result")
Â  Â  Â  Â  Â  Â  formatted_label = predicted_label_raw.replace('_', ' ').title()
Â  Â  Â  Â  Â  Â  if predicted_label_raw == 'normal':
Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"Detected Activity: **{formatted_label}** âœ…")
Â  Â  Â  Â  Â  Â  Â  Â  st.info("The model detects normal, non-intrusive network activity.")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"Detected Activity: **{formatted_label}** ðŸš¨")
Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"The model detects an intrusion of type: **{formatted_label}**.")
Â  Â  Â  Â  Â  Â  Â  Â  st.info("Proceed accordingly to mitigate the intrusion.")

Â  Â  Â  Â  Â  Â  # Display prediction probabilities
Â  Â  Â  Â  Â  Â  prediction_proba = rf_model.predict_proba(input_processed_df)
Â  Â  Â  Â  Â  Â  proba_df = pd.DataFrame(prediction_proba, columns=label_encoder.classes_)
Â  Â  Â  Â  Â  Â  st.write("Prediction Probabilities:")
Â  Â  Â  Â  Â  Â  st.dataframe(proba_df)

else:
Â  Â  st.error("App could not load data or train the model. Please check the data URL and file format.")